{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean Normalization\n",
    "\n",
    "In machine learning we use large amounts of data to train our models. Some machine learning algorithms may require that the data is *normalized* in order to work correctly. The idea of normalization, also known as *feature scaling*, is to ensure that all the data is on a similar scale, *i.e.* that all the data takes on a similar range of values. For example, we might have a dataset that has values between 0 and 5,000. By normalizing the data we can make the range of values be between 0 and 1.\n",
    "\n",
    "In this lab, you will be performing a different kind of feature scaling known as *mean normalization*. Mean normalization will scale the data, but instead of making the values be between 0 and 1, it will distribute the values evenly in some small interval around zero. For example, if we have a dataset that has values between 0 and 5,000, after mean normalization the range of values will be distributed in some small range around 0, for example between -3 to 3. Because the range of values are distributed evenly around zero, this guarantees that the average (mean) of all elements will be zero. Therefore, when you perform *mean normalization* your data will not only be scaled but it will also have an average of zero. \n",
    "\n",
    "# To Do:\n",
    "\n",
    "You will start by importing NumPy and creating a rank 2 ndarray of random integers between 0 and 5,000 (inclusive) with 1000 rows and 20 columns. This array will simulate a dataset with a wide range of values. Fill in the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 20)\n",
      "[[3202 4480  685 ... 1368  380   59]\n",
      " [4331 1611 1516 ...  606  971  401]\n",
      " [1549 1777  676 ... 1155 2749 4676]\n",
      " ...\n",
      " [1776 4134 1187 ... 1980  247 3885]\n",
      " [3390 1314 4679 ... 3802 4326  879]\n",
      " [1384 2635 4840 ... 2781 4269 4605]]\n",
      "[4331 1611 1516 3965 2333 4839  507 1891 4123 2693  509 1735 1332 2596\n",
      " 1896 2618 4387  606  971  401]\n"
     ]
    }
   ],
   "source": [
    "# import NumPy into Python\n",
    "import numpy as np\n",
    "\n",
    "# Create a 1000 x 20 ndarray with random integers in the half-open interval [0, 5001).\n",
    "X = np.random.randint(0,5001, size=[1000,20])\n",
    "\n",
    "# print the shape of X\n",
    "print(X.shape)\n",
    "print(X)\n",
    "print(X[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you created the array we will mean normalize it. We will perform mean normalization using the following equation:\n",
    "\n",
    "$\\mbox{Norm_Col}_i = \\frac{\\mbox{Col}_i - \\mu_i}{\\sigma_i}$\n",
    "\n",
    "where $\\mbox{Col}_i$ is the $i$th column of $X$, $\\mu_i$ is average of the values in the $i$th column of $X$, and $\\sigma_i$ is the standard deviation of the values in the $i$th column of $X$. In other words, mean normalization is performed by subtracting from each column of $X$ the average of its values, and then by dividing by the standard deviation of its values. In the space below, you will first calculate the average and standard deviation of each column of $X$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2490.114 2487.737 2454.963 2467.57  2491.399 2483.812 2538.675 2496.572\n",
      " 2507.797 2462.663 2610.714 2453.892 2431.447 2550.711 2498.449 2591.265\n",
      " 2510.828 2537.845 2449.891 2513.255]\n",
      "[1460.28299552 1434.89633905 1449.00599779 1411.09675044 1441.34951896\n",
      " 1414.3937891  1410.69505612 1449.88458189 1434.90346846 1468.14746379\n",
      " 1470.73989346 1451.89630082 1443.49147389 1470.23589858 1422.25619753\n",
      " 1452.89631384 1421.47346666 1437.48861873 1467.44934465 1432.7845979 ]\n",
      "[[3202 4480  685 ... 1368  380   59]\n",
      " [4331 1611 1516 ...  606  971  401]\n",
      " [1549 1777  676 ... 1155 2749 4676]\n",
      " ...\n",
      " [1776 4134 1187 ... 1980  247 3885]\n",
      " [3390 1314 4679 ... 3802 4326  879]\n",
      " [1384 2635 4840 ... 2781 4269 4605]]\n"
     ]
    }
   ],
   "source": [
    "# Average of the values in each column of X\n",
    "ave_cols = X.mean(axis=0)\n",
    "print(ave_cols)\n",
    "\n",
    "# Standard Deviation of the values in each column of X\n",
    "std_cols = X.std(axis = 0)\n",
    "print(std_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have done the above calculations correctly, then `ave_cols` and `std_cols`, should both be vectors with shape `(20,)` since $X$ has 20 columns. You can verify this by filling the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20,)\n",
      "(20,)\n"
     ]
    }
   ],
   "source": [
    "# Print the shape of ave_cols\n",
    "print(ave_cols.shape)\n",
    "\n",
    "# Print the shape of std_cols\n",
    "print(std_cols.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now take advantage of Broadcasting to calculate the mean normalized version of $X$ in just one line of code using the equation above. Fill in the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.26063647 -0.61101069 -0.64800491  1.06118167 -0.10989631  1.6651572\n",
      " -1.44019431 -0.41766911  1.12565273  0.15688955 -1.42901815 -0.49514005\n",
      " -0.76165812  0.0308039  -0.42358683  0.01840118  1.31987831 -1.34390281\n",
      " -1.00779697 -1.47423067]\n"
     ]
    }
   ],
   "source": [
    "# Mean normalize X\n",
    "X_norm = (X - ave_cols) / std_cols\n",
    "print(X_norm[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have performed the mean normalization correctly, then the average of all the elements in $X_{\\tiny{\\mbox{norm}}}$ should be close to zero, and they should be evenly distributed in some small interval around zero. You can verify this by filing the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3.1974423109204507e-18\n",
      "-1.7312099310720992\n",
      "1.7298585087349825\n"
     ]
    }
   ],
   "source": [
    "# Print the average of all the values of X_norm\n",
    "print(X_norm.mean())\n",
    "\n",
    "# Print the average of the minimum value in each column of X_norm\n",
    "print(X_norm.min(axis = 0).mean())\n",
    "\n",
    "# Print the average of the maximum value in each column of X_norm\n",
    "print(X_norm.max(axis = 0).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should note that since $X$ was created using random integers, the above values will vary. \n",
    "\n",
    "# Data Separation\n",
    "\n",
    "After the data has been mean normalized, it is customary in machine learnig to split our dataset into three sets:\n",
    "\n",
    "1. A Training Set\n",
    "2. A Cross Validation Set\n",
    "3. A Test Set\n",
    "\n",
    "The dataset is usually divided such that the Training Set contains 60% of the data, the Cross Validation Set contains 20% of the data, and the Test Set contains 20% of the data. \n",
    "\n",
    "In this part of the lab you will separate `X_norm` into a Training Set, Cross Validation Set, and a Test Set. Each data set will contain rows of `X_norm` chosen at random, making sure that we don't pick the same row twice. This will guarantee that all the rows of `X_norm` are chosen and randomly distributed among the three new sets.\n",
    "\n",
    "You will start by creating a rank 1 ndarray that contains a random permutation of the row indices of `X_norm`. You can do this by using the `np.random.permutation()` function. The `np.random.permutation(N)` function creates a random permutation of integers from 0 to `N - 1`. Let's see an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We create a random permutation of integers 0 to 4\n",
    "np.random.permutation(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To Do\n",
    "\n",
    "In the space below create a rank 1 ndarray that contains a random permutation of the row indices of `X_norm`. You can do this in one line of code by extracting the number of rows of `X_norm` using the `shape` attribute and then passing it to the  `np.random.permutation()` function. Remember the `shape` attribute returns a tuple with two numbers in the form `(rows,columns)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[655 556 441 325 887 231 820 119 257 961 255  85 958 296 734 222 294 844\n",
      " 606 883 927 951 259 299 566 375  88 438 884 396 544 413 502 581 487 759\n",
      " 931 965 782 716 731 861 235 914 725 509 238 282 570 870  11 301 180 799\n",
      "  77 159 464 836 504 684 292 324 786 310 804 991 133 541 741 772 765 244\n",
      " 916   9 890   7 213 847 383 585 516 776 718  69 840 386 700 333 586 882\n",
      " 641 410 411 595 963 945 484 680 179 543 561 922 520  35 949 362 843 492\n",
      " 512 161 498  73 899 697 901  38 258 351 637 573 875 999 443 618 873 177\n",
      " 609 175 592 677 651 750 335 218  93 385 346 323 997 791 913 910 427 649\n",
      " 932 407 193 358 185 280 421 228 104 401 363 339 500 738 121 674 130 397\n",
      " 646 533 885 548 819 852 778 227 357 962 477 474  81 691 937 792 611 139\n",
      " 850 876  47 306 976  16 261 155 676 217 508 993 752 326  49 967 699 801\n",
      " 476 886 102  14 983 514  18 281 493 764  43 633 195 797 124  56 826  22\n",
      " 429 703 569 822 675 898 971 445 934 425 100 616  80 194 270 462 969 466\n",
      " 707 933 625 475 755 770 334 182 810 713 108   4  59 748 709 834 775 948\n",
      " 865 774 392 908 518 727 794 199 122  45  28 467 431 348 647 480  60 798\n",
      " 365 954 757 973 269 705 434 591 485 588 919  66  50 174 308 565 992 531\n",
      " 359 319 802 943 990 361  31 188 853 347 639 116 428 303 373 202 563 395\n",
      " 605 209 377 631 153 422 285 488  82 695  83 593 739 972 252 549 857 891\n",
      " 453 432 622   3 405  10 894  89 596 289 832 831 109 602 113 880 942 722\n",
      " 619 555  79 760 200 929 670 449 968 773 756 829 379 547 749 987 912 491\n",
      " 970 507 456 526 926 985 439 950 371 147  58 766 835 321  25 344 664 771\n",
      " 196 747 478 813 665 426 220 623 607 604 128  55 980 621 465 237 268 103\n",
      " 245 956 170 489 888 787 617 408 435 311 730 859 437 254 996 790 902 858\n",
      "  74  21 284 594 660 715 981 877 322 264 906 688 455 638  42 450 893 184\n",
      "  61 511 382  36 777 779  29 412 955 589 524 938 135 838 110 636  65 964\n",
      " 156 667 123 578 393 571 446 537 628 872  54 528  13 342 803 576 293 698\n",
      " 304 659 740 921 567 225 783 995  94 444 701 809 704 403 391 160 640 136\n",
      " 598 169  57 164 249 874 816 846 208 157 708 203 744 763  64 984 404 105\n",
      " 173  20 219  24 941 206 866 583 603 979 601  33  91 505 388 960 626 751\n",
      " 243 288 242 917 795 643 815  76 314 925  53 297 711 162 896 141 878 265\n",
      " 263  70 232 433 582 430 163 313  37 845 862 753 869 855 230 328 728  51\n",
      " 793 129 889 545 211 918 106 988 290 909 240 186 683 868 176 574 172 118\n",
      "  92 448 107 920 350 380 341 309 729 501  68 682 191  19 496 497 864 312\n",
      " 327 317 114 678 673 307 420 513 923 152 769 851 337 642 189 657  78  52\n",
      " 654 499 808 378 998 117 318 515 461 696 132 369 624 580 364 720 562 723\n",
      " 416 201 149  17 256 482 568 897 440 246 111 959 746  98 837 143 721 144\n",
      " 368 253 966 389 994 187 811 495 272 745 644 302 134 503 788  40 271 546\n",
      " 251 632 978 627 584   5 329 732 142 457 935 436 827 824 564 315 167 977\n",
      " 905  39 112 599  90 127 154 694 250 146 276 881 210 974 557 207 681 283\n",
      " 131 743 608 719 305 145 279 690 376 530 761  67 120 190 418 406 784 316\n",
      " 126 171 409 590 767 535 800 879 205 166 367 781 702  99   6 558 915  32\n",
      " 560  15 224 278 629 536 506 662 260 986  62 895 814 936 529  30 658 494\n",
      " 197 140 390 267 939   1 398 839 572 151 575 521 394 181 158 717 652 523\n",
      " 470 125 796 165 415 525 989 331 469 442 527  44  27 183  12 656 343 366\n",
      " 903 733 817 710 540 115 553 336 534 402 275 539 768 848  97 471 807 600\n",
      " 345 277 354 330 849 724 481 417 479 830 223 610  48 692 789 614 982 957\n",
      " 825  46 736 818   8 399 928 854 559 178 577 663 944 860 620  26 812 519\n",
      " 648 737 805 226 400 414 856 468 458 349 387 360 332 353 286 198 490 613\n",
      "  72 483 904 685 248 946 148 821 460 287 780 871 947 552 550 806 486 338\n",
      " 241 579 758 216 907 168 669  41   2 828 930 239 587 150 300 423 274 785\n",
      " 634 247 823 138   0 952 355 101  86 419  71 236 650 863 212 686 975 672\n",
      " 192 447 463 953 645 522 597 653 356  63 542 298 451 900 687 726 551 510\n",
      " 712  75 229 291 295 454 473 924 320 215 532 867 693 615 233 221 841 137\n",
      " 234 689 538 940 204 340 452 892 517  84  34 266 372 666 679 742  23 762\n",
      " 668 374 671 630 424 214 262 833 381  95 911 472 842 370 554 612 273 706\n",
      " 459 661 754  87  96 735 352 714 635 384]\n"
     ]
    }
   ],
   "source": [
    "# Create a rank 1 ndarray that contains a random permutation of the row indices of `X_norm`\n",
    "row_indices = np.random.permutation(X_norm.shape[0])\n",
    "print(row_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can create the three datasets using the `row_indices` ndarray to select the rows that will go into each dataset. Rememeber that the Training Set contains 60% of the data, the Cross Validation Set contains 20% of the data, and the Test Set contains 20% of the data. Each set requires just one line of code to create. Fill in the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make any necessary calculations.\n",
    "# You can save your calculations into variables to use later.\n",
    "sixty = int(len(X_norm)*0.6)\n",
    "eighty = int(len(X_norm)*0.8)\n",
    "\n",
    "# Create a Training Set\n",
    "X_train = X_norm[row_indices[:sixty]]\n",
    "\n",
    "# Create a Cross Validation Set\n",
    "X_crossVal = X_norm[row_indices[sixty:eighty]]\n",
    "\n",
    "# Create a Test Set\n",
    "X_test = X_norm[row_indices[eighty:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you performed the above calculations correctly, then `X_tain` should have 600 rows and 20 columns, `X_crossVal` should have 200 rows and 20 columns, and `X_test` should have 200 rows and 20 columns. You can verify this by filling the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.6485825  -0.70648797  0.47138314 -1.45600931 -1.36982666 -0.31519652\n",
      " -0.68595619  1.56731648 -1.01943931  1.38973574 -1.75674435 -1.27894258\n",
      " -0.47554628 -0.72417698  1.08598648 -0.3608413   0.91958945  1.16881273\n",
      "  1.05905461 -1.29834938]\n",
      "[-0.6485825  -0.70648797  0.47138314 -1.45600931 -1.36982666 -0.31519652\n",
      " -0.68595619  1.56731648 -1.01943931  1.38973574 -1.75674435 -1.27894258\n",
      " -0.47554628 -0.72417698  1.08598648 -0.3608413   0.91958945  1.16881273\n",
      "  1.05905461 -1.29834938]\n",
      "(600, 20)\n",
      "[-0.95811155  0.78490896  1.65909389  1.12779652  0.20022971 -1.3064339\n",
      " -1.42318142  1.11348725  0.825981    1.65673889 -1.19036276  0.09994378\n",
      " -0.77343512 -0.76022562 -0.68795552 -0.3505171  -0.74558409  0.14202199\n",
      " -1.07662388 -0.61925219]\n",
      "[-0.95811155  0.78490896  1.65909389  1.12779652  0.20022971 -1.3064339\n",
      " -1.42318142  1.11348725  0.825981    1.65673889 -1.19036276  0.09994378\n",
      " -0.77343512 -0.76022562 -0.68795552 -0.3505171  -0.74558409  0.14202199\n",
      " -1.07662388 -0.61925219]\n",
      "(200, 20)\n",
      "[-1.47581942  0.35003434  0.62114098  0.80393495 -0.1001832   1.05288075\n",
      "  0.28661403  1.10590044 -0.7650668  -0.54263146  0.48294468 -0.53026652\n",
      "  0.19712829  1.45370481 -1.69621268  1.34884711 -0.70056039  0.25471854\n",
      "  1.22601097 -0.94239916]\n",
      "[-1.47581942  0.35003434  0.62114098  0.80393495 -0.1001832   1.05288075\n",
      "  0.28661403  1.10590044 -0.7650668  -0.54263146  0.48294468 -0.53026652\n",
      "  0.19712829  1.45370481 -1.69621268  1.34884711 -0.70056039  0.25471854\n",
      "  1.22601097 -0.94239916]\n",
      "(200, 20)\n"
     ]
    }
   ],
   "source": [
    "# Print the shape of X_train\n",
    "print(X_train[0])\n",
    "print(X_norm[row_indices[0]])\n",
    "print(X_train.shape)\n",
    "\n",
    "# Print the shape of X_crossVal\n",
    "print(X_crossVal[0])\n",
    "print(X_norm[row_indices[600]])\n",
    "print(X_crossVal.shape)\n",
    "\n",
    "# Print the shape of X_test\n",
    "print(X_test[0])\n",
    "print(X_norm[row_indices[800]])\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
